{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFL8go2pvw3KU5sm5i9iAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riyajivani/Amazon_web_scrapping/blob/main/web_scraping_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYFj4E-NWYGR"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def get_name(soup):\n",
        "  try:\n",
        "    name = soup.find(\"span\",attrs={'id':'productTitle'})\n",
        "    name_text = name.text\n",
        "    name_string = name_text.strip()\n",
        "\n",
        "  except:\n",
        "    name_string = \"\"\n",
        "\n",
        "  return name_string\n",
        "\n",
        "\n",
        "def get_price(soup):\n",
        "  try:\n",
        "    price = soup.find(\"span\",attrs={'class':'a-offscreen'}).text.strip()\n",
        "    # price_text = price.text\n",
        "    # price_string = price_text.strip()\n",
        "\n",
        "  except:\n",
        "    price = \"\"\n",
        "\n",
        "  return price\n",
        "\n",
        "\n",
        "input = input(\"enter the name of item...\")\n",
        "\n",
        "url = \"https://www.amazon.in/s?k=\" + input\n",
        "HEADERS = ({'User-Agent': 'https://explore.whatismybrowser.com/useragents/parse/?analyse-my-user-agent=yes', 'Accept-Language':'en-US, en;q=0.5'})\n",
        "\n",
        "\n",
        "response = requests.get(url, headers=HEADERS)\n",
        "# response.content\n",
        "\n",
        "\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "# soup\n",
        "\n",
        "\n",
        "links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
        "\n",
        "#links\n",
        "# links[0]\n",
        "# link = links[0].get('href')\n",
        "# product_link = \"https://amazon.in\" + link\n",
        "# # product_link\n",
        "# new_response = requests.get(product_link,headers=HEADERS)\n",
        "# # new_response\n",
        "# new_soup = BeautifulSoup(new_response.content, \"html.parser\")\n",
        "# # new_soup\n",
        "# new_soup.find(\"span\",attrs={'id':'productTitle'}).text.strip()\n",
        "# new_soup.find(\"span\",attrs={'class':'a-offscreen'}).text.strip()\n",
        "\n",
        "\n",
        "heel_list = []\n",
        "\n",
        "for link in links:\n",
        "  heel_list.append(link.get('href'))\n",
        "\n",
        "heel_data = {\"name\":[],\"price\":[]}\n",
        "\n",
        "\n",
        "for link in heel_list:\n",
        "  new_response = requests.get(\"https://amazon.in\" + link, headers=HEADERS)\n",
        "  new_soup = BeautifulSoup(new_response.content, \"html.parser\")\n",
        "\n",
        "  heel_data['name'].append(get_name(new_soup))\n",
        "  heel_data['price'].append(get_price(new_soup))\n",
        "\n",
        "amazon_df = pd.DataFrame.from_dict(heel_data)\n",
        "amazon_df['name'].replace('', np.nan, inplace=True)\n",
        "amazon_df = amazon_df.dropna(subset=['name'])\n",
        "amazon_df['price'].replace('', np.nan, inplace=True)\n",
        "amazon_df = amazon_df.dropna(subset=['price'])\n",
        "amazon_df.to_csv(\"amazon_data_final.csv\",header=True, index=False)\n",
        "\n",
        "\n",
        "\n",
        "amazon_df\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}