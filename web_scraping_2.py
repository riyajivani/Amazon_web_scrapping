# -*- coding: utf-8 -*-
"""web_scraping_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zeqO23HuLcHOQrxfWdeDUWLs4UUB3AuW
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import time

def get_name(soup):
  try:
    name = soup.find("span",attrs={'id':'productTitle'})
    name_text = name.text
    name_string = name_text.strip()

  except:
    name_string = ""

  return name_string


def get_price(soup):
  try:
    price = soup.find("span",attrs={'class':'a-offscreen'}).text.strip()
    # price_text = price.text
    # price_string = price_text.strip()

  except:
    price = ""

  return price




url = "https://www.amazon.in/s?k=heels+for+women&crid=258DREB995ODS&sprefix=heels%2Caps%2C222&ref=nb_sb_ss_ts-doa-p_3_5"
HEADERS = ({'User-Agent': 'https://explore.whatismybrowser.com/useragents/parse/?analyse-my-user-agent=yes', 'Accept-Language':'en-US, en;q=0.5'})


response = requests.get(url, headers=HEADERS)
# response.content


soup = BeautifulSoup(response.content, "html.parser")
# soup


links = soup.find_all("a", attrs={'class':'a-link-normal s-no-outline'})

#links
# links[0]
# link = links[0].get('href')
# product_link = "https://amazon.in" + link
# # product_link
# new_response = requests.get(product_link,headers=HEADERS)
# # new_response
# new_soup = BeautifulSoup(new_response.content, "html.parser")
# # new_soup
# new_soup.find("span",attrs={'id':'productTitle'}).text.strip()
# new_soup.find("span",attrs={'class':'a-offscreen'}).text.strip()


heel_list = []

for link in links:
  heel_list.append(link.get('href'))

heel_data = {"name":[],"price":[]}


for link in heel_list:
  new_response = requests.get("https://amazon.in" + link, headers=HEADERS)
  new_soup = BeautifulSoup(new_response.content, "html.parser")

  heel_data['name'].append(get_name(new_soup))
  heel_data['price'].append(get_price(new_soup))

amazon_df = pd.DataFrame.from_dict(heel_data)
amazon_df['name'].replace('', np.nan, inplace=True)
amazon_df = amazon_df.dropna(subset=['name'])
amazon_df['price'].replace('', np.nan, inplace=True)
amazon_df = amazon_df.dropna(subset=['price'])
amazon_df.to_csv("amazon_data_final.csv",header=True, index=False)



amazon_df